{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheniabosch/sql_business_exploration/blob/main/SB_ENIAC_case_study_CHI_SQUARE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "EoEKjxz7L_oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency"
      ],
      "metadata": {
        "id": "inAEOfwCMChk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data for experiment"
      ],
      "metadata": {
        "id": "urTH3nfd-lJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 importing Data"
      ],
      "metadata": {
        "id": "r5RTQ4ZZLFbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/file/d/18mPEn1pbX8wxwjlSHgJbV9p5ZAnXC7t9/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "eniac_a = pd.read_csv(path)\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1WCzwDDjATFsR_ZY_y3wwBy9T_PtWB6l6/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "eniac_b = pd.read_csv(path)\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1s_XE9YLhuSN9phcukmFPjS5QxqRC5IFM/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "eniac_c = pd.read_csv(path)\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1eOPqJBKT0AHyBpPgEGCJszlDf9ZUrk_0/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "eniac_d = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "5nRdaov_LJqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Experiment"
      ],
      "metadata": {
        "id": "dwyWgjRrZgF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have 4 samples and the data is categorical (\"click\" or \"no click\"), we are going to check if our tests resault statistically significant or not with Chi-swuared test."
      ],
      "metadata": {
        "id": "C7hNptH7Zixp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Stating the Null and the Alternative Hypotheses."
      ],
      "metadata": {
        "id": "v7i9lJyqbmqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H_o$ : The 4 versions of the button are equally likely to receive clicks, and the observed differences are due to chance.\n",
        "\n",
        "$H_1$ : The observed differences are not due to chance: there is at least one version that got so many more/much less clicks than the others that this can hardly be explained just by chance"
      ],
      "metadata": {
        "id": "XvxUxJTobpR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 Defining the alpha."
      ],
      "metadata": {
        "id": "wrPZEkewcCNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since making type | error is less important than making type || error in our case, we are going to wide our threshold here with being 90% confident."
      ],
      "metadata": {
        "id": "q6L8t4HEcK0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05"
      ],
      "metadata": {
        "id": "pK09VC9rd82l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.3 Collecting Data"
      ],
      "metadata": {
        "id": "gtzYkAIud_Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visit_a = 25326\n",
        "click_a = eniac_a['No. clicks'].loc[eniac_a['Name'] == 'SHOP NOW'].squeeze()\n",
        "no_click_a = visit_a - click_a\n",
        "\n",
        "visit_b = 24747\n",
        "click_b = eniac_b['No. clicks'].loc[eniac_b['Name'] == 'SHOP NOW'].squeeze()\n",
        "no_click_b = visit_b - click_b\n",
        "\n",
        "visit_c = 24876\n",
        "click_c = eniac_c['No. clicks'].loc[eniac_c['Name'] == 'SEE DEALS'].squeeze()\n",
        "no_click_c = visit_c - click_c\n",
        "\n",
        "visit_d = 25233\n",
        "click_d = eniac_d['No. clicks'].loc[eniac_d['Name'] == 'SEE DEALS'].squeeze()\n",
        "no_click_d = visit_d - click_d\n",
        "\n",
        "\n",
        "observed_data = pd.DataFrame([[click_a, click_b, click_c, click_d],[no_click_a, no_click_b, no_click_c, no_click_d]], columns=['Ver_A', 'Ver_B', 'Ver_C', 'Ver_D'], index=['Click', 'No_Click'])"
      ],
      "metadata": {
        "id": "G7fZcpzceSOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.4 Calculating Test Resualt"
      ],
      "metadata": {
        "id": "ZFbWNx4defyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chisq, pvalue, df, excepted = chi2_contingency(observed_data)"
      ],
      "metadata": {
        "id": "TVsvN2g4ejrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.5 Interpreting the test resault"
      ],
      "metadata": {
        "id": "5gyagQw2ews2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if pvalue < alpha:\n",
        "  print('we are rejecting the null hypothesis, CTR of 4 versions are not equal, and the differences is not by chance.')\n",
        "else:\n",
        "  print('we dont have enough evidence to reject the null hypothesis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLaVj2ORe34x",
        "outputId": "06a18569-b2c8-458f-e85e-50e8d92e96a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are rejecting the null hypothesis, CTR of 4 versions are not equal, and the differences is not by chance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.6 Post-hoc"
      ],
      "metadata": {
        "id": "Mfb_DVe34RCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we came to resault that 4 versions CTR difference didnt occur by chance and they are indeed acting different, we need to do a post-hoc test."
      ],
      "metadata": {
        "id": "C9P-UFWi4TnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating CTR for each version\n",
        "ctr_dict = {}\n",
        "\n",
        "for vers in observed_data.columns:\n",
        "  clicks = observed_data.loc['Click', vers]\n",
        "  no_click = observed_data.loc['No_Click', vers]\n",
        "  ctr = round(clicks/(clicks+no_click)*100, 2)\n",
        "  ctr_dict[vers] = ctr"
      ],
      "metadata": {
        "id": "q7f8bDjr-FjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ver_q = observed_data.shape[1]\n",
        "number_of_tests = int(ver_q*(ver_q-1)/2)\n",
        "alpha_posthoc = alpha/number_of_tests\n",
        "\n",
        "ver_names = observed_data.columns.tolist()\n",
        "\n",
        "significant_resaults = []\n",
        "\n",
        "for i in range(ver_q):\n",
        "    ver1_name = ver_names[i]\n",
        "    for j in range(i+1, ver_q):\n",
        "        ver2_name = ver_names[j]\n",
        "\n",
        "        click1 = observed_data.loc['Click', ver1_name]\n",
        "        no_click1 = observed_data.loc['No_Click', ver1_name]\n",
        "\n",
        "        click2 = observed_data.loc['Click', ver2_name]\n",
        "        no_click2 = observed_data.loc['No_Click', ver2_name]\n",
        "\n",
        "        paired_vers = [[click1, no_click1],[click2, no_click2]]\n",
        "\n",
        "        chisq, pvalue, df, excepted = chi2_contingency(paired_vers)\n",
        "\n",
        "        if pvalue < alpha_posthoc:\n",
        "\n",
        "            ctr1 = ctr_dict[ver1_name]\n",
        "            ctr2 = ctr_dict[ver2_name]\n",
        "\n",
        "            if ctr1 > ctr2:\n",
        "                significant_resaults.append(f\"{ver1_name} (CTR: {ctr1:.2f}%) > {ver2_name} (CTR: {ctr2:.2f}%)\")\n",
        "                print(f\"  CONCLUSION: {ver1_name} (CTR: {ctr1:.2f}%) is significantly BETTER than {ver2_name} (CTR: {ctr2:.2f}%)\")\n",
        "            else:\n",
        "                significant_resaults.append(f\"{ver2_name} (CTR: {ctr2:.2f}%) > {ver1_name} (CTR: {ctr1:.2f}%)\")\n",
        "                print(f\"  CONCLUSION: {ver2_name} (CTR: {ctr2:.2f}%) is significantly BETTER than {ver1_name} (CTR: {ctr1:.2f}%)\")\n",
        "        else:\n",
        "            print(f\"  CONCLUSION: No significant difference between {ver1_name} and {ver2_name}\")\n",
        "\n",
        "if significant_resaults:\n",
        "  for v, c in sorted(ctr_dict.items(), key=lambda item: item[1], reverse=True):\n",
        "    print(f\" {v}: {c: .2f}%\")\n",
        "else:\n",
        "    print(\"No statistically significant differences were found between any pairs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zpLdZFGh4_EY",
        "outputId": "2817e104-1390-40c6-d65a-d2d5ef5a038a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CONCLUSION: Ver_A (CTR: 2.02%) is significantly BETTER than Ver_B (CTR: 1.14%)\n",
            "  CONCLUSION: No significant difference between Ver_A and Ver_C\n",
            "  CONCLUSION: Ver_A (CTR: 2.02%) is significantly BETTER than Ver_D (CTR: 0.76%)\n",
            "  CONCLUSION: Ver_C (CTR: 2.12%) is significantly BETTER than Ver_B (CTR: 1.14%)\n",
            "  CONCLUSION: Ver_B (CTR: 1.14%) is significantly BETTER than Ver_D (CTR: 0.76%)\n",
            "  CONCLUSION: Ver_C (CTR: 2.12%) is significantly BETTER than Ver_D (CTR: 0.76%)\n",
            " Ver_C:  2.12%\n",
            " Ver_A:  2.02%\n",
            " Ver_B:  1.14%\n",
            " Ver_D:  0.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n9MLj86-Pz0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation with HPR and DOR"
      ],
      "metadata": {
        "id": "QNcXil_CP10H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop off rate:\n",
        "dor_a =.09\n",
        "dor_b =0\n",
        "dor_c =.13\n",
        "dor_d =.125\n"
      ],
      "metadata": {
        "id": "IFKXPwUlF7XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#homepage return rate\n",
        "hpr_a =0.051\n",
        "hpr_b =0\n",
        "hpr_c =0.048\n",
        "hpr_d =0.26"
      ],
      "metadata": {
        "id": "ICmL0yG7GgoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CTR values (higher is better)\n",
        "ctrs = {\n",
        "    'A': 2.02,\n",
        "    'B': 1.14,\n",
        "    'C': 2.12,\n",
        "    'D': 0.76\n",
        "}\n",
        "\n",
        "# Drop-Off Rates (lower is better)\n",
        "dors = {\n",
        "    'A': 0.09,\n",
        "    'B': 0.00,\n",
        "    'C': 0.13,\n",
        "    'D': 0.125\n",
        "}\n",
        "\n",
        "# Homepage Return Rates (lower is better)\n",
        "hprs = {\n",
        "    'A': 0.051,\n",
        "    'B': 0.00,\n",
        "    'C': 0.048,\n",
        "    'D': 0.26\n",
        "}\n",
        "\n",
        "# Normalize function\n",
        "def normalize(metric_dict, reverse=False):\n",
        "    values = list(metric_dict.values())\n",
        "    min_val = min(values)\n",
        "    max_val = max(values)\n",
        "    if max_val == min_val:\n",
        "        return {k: 0.5 for k in metric_dict}  # handle division by zero\n",
        "    return {\n",
        "        k: (1 - (v - min_val) / (max_val - min_val)) if reverse else ((v - min_val) / (max_val - min_val))\n",
        "        for k, v in metric_dict.items()\n",
        "    }\n",
        "\n",
        "# Normalize each metric\n",
        "norm_ctr = normalize(ctrs)          # higher is better\n",
        "norm_dor = normalize(dors, True)    # lower is better\n",
        "norm_hpr = normalize(hprs, True)    # lower is better\n",
        "\n",
        "# Weight for each metric (adjust as needed)\n",
        "weights = {\n",
        "    'ctr': 0.5,\n",
        "    'dor': 0.25,\n",
        "    'hpr': 0.25\n",
        "}\n",
        "\n",
        "# Compute final score\n",
        "scores = {}\n",
        "for version in ctrs.keys():\n",
        "    scores[version] = (\n",
        "        norm_ctr[version] * weights['ctr'] +\n",
        "        norm_dor[version] * weights['dor'] +\n",
        "        norm_hpr[version] * weights['hpr']\n",
        "    )\n",
        "\n",
        "# Rank versions\n",
        "ranked_versions = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Output\n",
        "print(\"Overall Ranking:\")\n",
        "for i, (version, score) in enumerate(ranked_versions, 1):\n",
        "    print(f\"{i}. Version_{version} - Score: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "FKYBVLw3Lq2g",
        "outputId": "a19354f8-7065-4caf-8d3e-d91acd78f4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Ranking:\n",
            "1. Version_A - Score: 0.7411\n",
            "2. Version_C - Score: 0.7038\n",
            "3. Version_B - Score: 0.6397\n",
            "4. Version_D - Score: 0.0096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final conclustion is to reject the null hypothesis. Version A is significantly better performing then versions B, C, and D.\n",
        "Eniac should continue to use the white shop now button.\n",
        "Investigations should also be made into the data collection errors that occured with version B HPR and DOR collection."
      ],
      "metadata": {
        "id": "FAM0Kl7QLuow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **note**\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
        "\n",
        "dispays a short version of longer numbers, use instead of rounding floats\n",
        "\n",
        "\n",
        "check bounnc rate to, its in the code above\n",
        "\n",
        "create a visualization to round out as a project"
      ],
      "metadata": {
        "id": "1thX-veljSR8"
      }
    }
  ]
}